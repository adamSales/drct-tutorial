---
title: "Estimating Effects from a Bernoulli Experiment: Solutions"
output: html_notebook
---

This notebook will guide you through the process of estimating a treatment effect from a randomized A/B test, using the new `dRCT` package in `R`.

## Estimating an Average Effect with Just RCT data

### Step 0: Install the `dRCT` package (only do this once)

The package only needs to be installed once--after that you can skip this step

```{r}
if(!require(devtools)) install.packages('devtools')
if(!require(dRCT)) devtools::install_github("manncz/dRCT",upgrade = FALSE)
```

### Step 1: Load in the package

(run this line each time you start `R`)

```{r}
library(dRCT)
```

### Step 2: Load and Explore the Dataset

```{r}
abdat <- read.csv('../data/abTestExample.csv')
```

You may want to use one or more of these functions to explore the dataset's structure:

```{r}
View(abdat) ## opens a new tab in Rstudio
dim(abdat) ## the dimension of the datset (rows, columns)
names(abdat) ## variable names
head(abdat) ## first 6 rows
```

More information on the dataset is available [here](https://github.com/manncz/edm-rct-tutorial/blob/main/data/ABexampleDataDictionary.md).

### Step 3: Extract the necessary variables from the dataset

To estimate effects from a Bernoulli RCT, you really only need two variables:

1.  Treatment (the exposure, intervention, etc.)
2.  Outcome (What the the treatment is supposed to affect)

Extract the treatment variable from the dataset:

```{r}
# put something like Tr = abdat$variable 
# (for instance, if the variable name is "inter" then put Tr = abdat$inter)
Tr= abdat$video
```

Extract the outcome variable:

```{r}
# put something like Y = abdat$variable (e.g. Y= abdat$outcome)
Y = abdat$completion
```

### Interlude

With these two variables, you can estimate the average effect using a t-test:

```{r}
print(TTest <- t.test(Y~Tr))


```

the estimate is:

```{r}
TTest$estimate[2]-TTest$estimate[1]
```

with a standard error:

```{r}
TTest$stderr
```

The `loop()` function without covariates gives you the same answer:

```{r}
loop(Y=Y,Tr=Tr)
```

### Covariates

To get a precise answer, you'll want to use baseline covariates

Extract the covariates: identify which columns of the data matrix are baseline covariates, and create a new matrix or dataframe with only those columns. You can identify the columns numerically, like:

```         
covariates=abdat[,c(2,3,7,8)] ## for columns 2, 3, 7, 8
```

or

```         
covariates=abdat[,5:9] ## for columns 5,6,7,8,9
```

by name:

```         
covariates = abdat[,c("var1","var2","var3")]
```

or using regular expressions:

```         
covariates = abdat[,grep("pattern",names(abdat))]
```

```{r}
# put your code here
covariates= abdat[,2:10]
# or
covariates= abdat[,grep('student_prior',names(abdat))]
```

### Step 4: Estimate the average effect

One more ingredient is necessary to estimate effects from a Bernoulli RCT: the probability of a unit being assigned to the treatment condition. In this case, $Pr(Tr_i=1)=0.5$.

Then, to estimate effects, use the `loop()` function:

```{r}
est_loop=loop(Y=Y, Tr=Tr,Z=covariates,p=0.5)
```

To see the estimate, standard error, and a p-value testing the null hypothesis of no average effect, use `print()`:

```{r}
print(est_loop)
```

The `confint()` function gives confidence intervals:

```{r}
confint(est_loop)
```

## Incorporating Auxiliary Data

### Step 1: Gather auxiliary data and analogous experimental data

The file "auxiliaryLogData.csv" has data for a separate group of students who worked on a problem set similar to the one featured in the RCT. The dataset includes assignment-level student performance measurements for the previous five assignments each student worked on, along with student-level averages.
```{r}
aux_logdata <- read.csv('../data/auxiliaryLogData.csv')
```
The dataset "rctLogData.csv" includes the same predictors for the students in the RCT:
```{r}
rct_logdata <- read.csv('../data/rctLogData.csv')
```

### Step 2: Train a prediction algorithm 
Use the auxiliary dataset to train a prediction algorithm, predicting `completion` as a function of the predictors.

Here, you may use any algorithm you want--you may even use the auxiliary data to compare the results of several algorithms and then choose between them or ensemble them. 

In fact, the `SuperLearner` package does that all for you, so we'll use that. You may need to install it, but that should go quickly:
```{r}
if(!require(SuperLearner)) install.packages('SuperLearner')
library(SuperLearner)
```

The way `SuperLearner` works is that you provide a matrix or dataframe of predictors, `X`, and outcome `Y`, and a list of candidate prediction algorithms. To see the built-in options, run:
```{r}
listWrappers()
```

Choose your favorite algorithms from this list (bear in mind, some may require you to install yet more packages, and/or take a long time to run -- ahem, `SL.nnet`)

For instance, say we want to try regression, ridge regression, and 
a fast version of random forest called `ranger` (which may need to be installed). Then run:
```{r}
if(!require(ranger)) install.packages('ranger')
algs <- c('SL.lm','SL.ridge','SL.ranger')
```
Go ahead and edit that code, and re-run, if you want to try something different!

Then train the model using the auxiliary data:
```{r}
X <- aux_logdata
X$completion <- NULL

auxmod <- SuperLearner(Y=aux_logdata$completion,X=X,SL.library=algs)
```

The SuperLearner uses cross-validation to weight the candidate algorithms:
```{r}
auxmod
```


### Step 3: Get predictions for RCT students

Now, use the model from step 2 to generate predicted outcomes for the students in the RCT.
Here we'll use the `rct_logdata` dataset.
Note that we've conveniently arranged things so that the rows are in the right order:
```{r}
all.equal(rct_logdata$user_id, abdat$user_id)
```
To keep things simple, we'll remove that column:
```{r}
rct_logdata$user_id <- NULL
```
With a SuperLearner model, getting predictions is straightforward:

```{r}
yhat <- predict(auxmod,rct_logdata)
yhat <- yhat$pred[,1]
```

### Step 4: Use `loop`, along with the Auxiliary predictions, to estimate effects

The call is the same as before, except we use the `reloop` prediction algorithm, and 
include `yhat` as an additional argument:
```{r}
est_reloop <- loop(Y = Y, Tr = Tr, Z=covariates,p=0.5, pred = reloop, yhat=yhat)

print(est_reloop)
confint(est_reloop)
```


To replicate the result in [this JEDM article](https://jedm.educationaldatamining.org/index.php/JEDM/article/view/646),
first load in the predictions from that fancy-schmancy deep neural net:

```{r}
yhat_nn <- read.csv('../data/yhatNN.csv')[,1]
```
Then re-run the estimation routine:
```{r}
est_reloop <- loop(Y = Y, Tr = Tr, Z=covariates,p=0.5, pred = reloop, yhat=yhat_nn)

print(est_reloop)
confint(est_reloop)
```

## Estimating heterogeneous treatment effects (HTE)

### Step 1: Extract ITE estimates 
You can retrieve the estimated individual treatment effects (ITE) using the following command:
```{r}
tauhat <- getITE(est_reloop)
```

### Step 2: Fit moderation model


We will run a linear regression model, regressing the estimated ITE on the covariates to estimate the conditional average treatment effects (CATE). 


Simply run the model below:
```{r}
hteMod=lm(tauhat ~ ., data = covariates) 
```
### Step 3: Display and interpret the results:

To get the standard errors right, we need the `sandwich` package:
```{r}
if(!require(sandwich)){
  install.packages("sandwich")
  library(sandwich)
}
```
To display the coefficients with standard errors and p-values, use the `lmtest` package:
```{r}
if(!require(lmtest)){
  install.packages("lmtest")
  library(lmtest)
}
```

To display the results, use the `coeftest()` function:
```{r}
coeftest(hteMod)
```


Note that you can use any regression model to estimate the CATE this way. 

For instance, you can also use regression trees:
```{r}
if(!require(rpart)){
  install.packages('rpart')
  library(rpart)
}
cart <- rpart(tauhat~.,data=covariates)
cart
```

Plot the fitted model:
```{r}
if(!require(rpart.plot)){
  install.packages('rpart.plot')
  library(rpart.plot)
}
rpart.plot(cart)
```


Now, choose your own model, using `lm()`, `rpart()` or any other function you know of, to estimate heterogeneous effects:

```{r}
## put code here
```